{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 학습 과정\n",
    "\n",
    "데이터를 정수형으로 반환했으면 이진분류를 통해 학습하여 보자.\n",
    "\n",
    "---\n",
    "## (1)class Model\n",
    "\n",
    "모델 클래스에서는 필요한 가중치와 계산에 필요한 함수들로 구성된다.\n",
    "\n",
    "이진 분류의 핵심 계산함수(activate_function)는 sigmoid 함수이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "class Model:\n",
    "    def __init__(self):\n",
    "        self.weight = np.zeros((3, 1))\n",
    "        pass\n",
    "\n",
    "    def predict(self, x):\n",
    "        feature_matrix = x\n",
    "        z = feature_matrix @ self.weight\n",
    "        pred = self.activate(z)\n",
    "        return pred\n",
    "    \n",
    "    def activate(self, x):\n",
    "        y = 1/ (1+np.exp(-x))\n",
    "        return y\n",
    "    \n",
    "    def update(self, weight):\n",
    "        self.weight = weight\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2)class MyOptim\n",
    "\n",
    "myoptim 클래스에서는 학습률과 정규화 상수를 추가한다.\n",
    "\n",
    "학습률을 가중치의 변화량에 영향을 준다.\n",
    "\n",
    "또한 손실값과 잔차를 계산하여 최대 손실의 방향으로 (gradient)로 이동하여 학습한다.\n",
    "\n",
    "이때 학습이 잘 되는지 확인하기 위해 손실값을 반환하자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyOptim:\n",
    "    def __init__(self, model):\n",
    "        self.model  = model\n",
    "        self.eps    = 1e-8\n",
    "        self.lr = 0.1\n",
    "    def compute_loss(self, label, prediction):\n",
    "        # ===========================\n",
    "        eps = self.eps\n",
    "        loss = (1 / (len(label))) * ((((-1) * label.T) @ np.log(prediction + eps)) - ((np.ones_like(label) - label).T @ np.log(np.ones_like(label) - prediction + eps)))\n",
    "        # ===========================\n",
    "        return loss\n",
    "     \n",
    "    def compute_residual(self, label, prediction):\n",
    "        # ===========================\n",
    "        res = label - prediction\n",
    "        # ===========================\n",
    "        return res\n",
    "   \n",
    "    def compute_gradient(self, x, label, pred):\n",
    "        # ===========================\n",
    "        A = x\n",
    "        grad = (1 / (len(label))) * (A.T @ (pred - label))\n",
    "        # ===========================\n",
    "        return grad\n",
    "        \n",
    "    def step(self, grad):\n",
    "        # ===========================\n",
    "        weight = self.model.weight\n",
    "        next_weight = weight - (self.lr * grad)\n",
    "        self.model.update(next_weight)\n",
    "        pass \n",
    "        # ==========================="
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
